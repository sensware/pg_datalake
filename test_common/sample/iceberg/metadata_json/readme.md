
We have two sets of metadata files. The ones that start with numbers such as `00001-XXXX-.metadata.json` are generated by these DDL commands on spark:
```sql
spark-sql --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.1 \
    --conf spark.sql.catalog.my_catalog=org.apache.iceberg.spark.SparkCatalog \
    --conf spark.sql.catalog.hive_prod.type=hive \
    --conf spark.sql.catalog.my_catalog.warehouse=s3://cdwtestdatasets/test_spark_metadata/v3/ \
    --conf spark.sql.catalog.my_catalog.catalog-impl=org.apache.iceberg.jdbc.JdbcCatalog \
    --conf spark.sql.catalog.my_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO \
    --conf spark.sql.catalog.my_catalog.uri=jdbc:postgresql://localhost:5432/postgres \
    --conf spark.sql.catalog.my_catalog.jdbc.verifyServerCertificate=false \
    --conf spark.sql.catalog.my_catalog.jdbc.useSSL=true \
    --conf spark.sql.catalog.my_catalog.jdbc.user=onderkalaci \
    --conf spark.sql.catalog.my_catalog.jdbc.password=pass \
    --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
    --conf spark.sql.iceberg.collect-stats=true


-- create a partitioned table with many special chars all over the place
CREATE TABLE my_catalog.public.partitioned_table (
    id bigint NOT NULL COMMENT 'unique id',
    `data escape chars''!//\\ ` string NOT NULL,
    category string,
    ts timestamp)
USING iceberg
PARTITIONED BY (
    bucket(16, id), 
    days(ts), 
    bucket(8, `data escape chars''!//\\ `), 
    truncate(10, id)
)
TBLPROPERTIES ('key'='value', 'test'='data', '"mytest"'='"\yoi ur"');

ALTER TABLE my_catalog.public.partitioned_table SET IDENTIFIER FIELDS id, `data escape chars''!//\\ `;

ALTER TABLE my_catalog.public.partitioned_table SET TBLPROPERTIES ('read.split.target-size'='268435456');
ALTER TABLE my_catalog.public.partitioned_table SET TBLPROPERTIES ('comment' = 'A table comment with escape chars "\;\'.');
ALTER TABLE my_catalog.public.partitioned_table ADD COLUMNS (new_column string comment 'new_column docs with escape chars "\;\'.');
ALTER TABLE my_catalog.public.partitioned_table ADD COLUMN points map<struct<x: int>, struct<a: int>>;
ALTER TABLE my_catalog.public.partitioned_table ADD COLUMN point struct<x: double, y: double>;
ALTER TABLE my_catalog.public.partitioned_table ADD COLUMN point.z double;
ALTER TABLE my_catalog.public.partitioned_table ADD COLUMN points_arr array<struct<x: double, y: double>>;
ALTER TABLE my_catalog.public.partitioned_table ADD COLUMN points_arr.element.z double;
ALTER TABLE my_catalog.public.partitioned_table ADD PARTITION FIELD year(ts);
ALTER TABLE my_catalog.public.partitioned_table ALTER COLUMN category TYPE string;
ALTER TABLE my_catalog.public.partitioned_table WRITE ORDERED BY category ASC NULLS LAST, id DESC NULLS FIRST;
ALTER TABLE my_catalog.public.partitioned_table WRITE LOCALLY ORDERED BY category, id;
ALTER TABLE my_catalog.public.partitioned_table ADD PARTITION FIELD bucket(3, id)  AS shard;
ALTER TABLE my_catalog.public.partitioned_table CREATE BRANCH `a''\"udit-branch`;
ALTER TABLE my_catalog.public.partitioned_table CREATE BRANCH `a''\"udit-branch2`;
ALTER TABLE my_catalog.public.partitioned_table SET IDENTIFIER FIELDS id,  `data escape chars''!//\\ `;
ALTER TABLE my_catalog.public.partitioned_table RENAME COLUMN `data escape chars''!//\\ ` TO payload;

ALTER TABLE  my_catalog.public.partitioned_table RENAME TO  my_catalog.public.`partitioned table  2 escape chars''!//\\ `;

```

The rest are taken from https://github.com/apache/iceberg/blob/main/core/src/test/resources/.
